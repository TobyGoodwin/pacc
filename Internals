Source Files
============

Since pacc is partly written by pacc, it can all get a bit confusing!

emit.c - writes the output file from the AST

main.c - command line parsing, other glue

pacc.c - the packrat parser that constructs an AST from a .peg file;
constructed (by pacc) from pacc.peg

paccman.c - constructs an AST manually for bootstrapping

pacc.peg - the grammar description that is converted to pacc.c

syntax.c - support for the Abstract Syntax Tree constructed as the
grammar is read


Other Notes
===========

The key to (linear) packrat parsing is the memoization table that
squirrels away every result that the parser discovers about the input as
it is read. In a naive implementation, this is simply a matrix, with one
row for each rule of the grammar, and one column for each character of
the input. However, this matrix is (typically) very sparse, so pacc
tries to do better.

thoughts...

rows is of the order of 100 - it would be a pretty zany grammar that had
more than 1000 rules = ~7 bits

columns is of the order of 100000 - we should support inputs of 1
megabyte (or 10 or even 100 if possible), but most inputs will be *much*
smaller than that = ~16 bits

(should we consider swapping the memoization table ourselves, like sam?
or just bung it all in vm and hope for the best?)

so, thinking about a hash function for the matrix, we have about 23
bits of input, in two integers. that should be enough to do something
interesting...

---

Insight: we talk about semantic *actions*, and in ``yacc`` they are ``C``
program fragments, but really those things are expressions! In ``yacc``,
of course, the convention is that the program fragment delivers a value
by assigning to ``$$``. So these things are not really actions at all, but
*expressions*. They have values, and types.

How might we express this?

int Decimal <- d:'0' / d:'1' / ... { d - '0' }
int Decimal <- < [0-9] > { d - '0' } ???
struct Node *cmd <- ...
                 /  TWIDDLE optcaret s:word p:words { mk(nMatch, s, p) }
                 / ... 

Problems: braces around expressions look wrong... didn't Ford have a
different / better syntax? OK, all sorts of stuff coming out here (I
don't like Piumarta's < > syntax; ...). However, the idea of typing each
rule seems plausible. And the type of the first rule can become the
default type.

2009-06-17
----------

Pressing on with semantic expressions. Each rule has a type (worry about
defaulting later).

Rules of type "void" never yield a value, of course. Should we allow
expressions that are evaluated for their side effects? I guess so.
Clearly it is not legal to bind a name to a "void" rule.

Rules of most other types are fine: the semantic expression must yield a
value of the given type:

  int Additive <- m:Multitive '+' a:Additive { m + a }

But we need at least something else: a way to extract parts of the input
text. A rule of type [ haven't decided: either "char *", or some special
type like "text" ] has a default value (in the absence of a semantic
expression) of [ haven't decided: either the entire text matched by the
rule, or the concatenation of the parts of it that aren't matched by a
"void" call, or ... ]. This default value is freshly allocated by a call
to realloc() - to use your own memory allocator, simply #define realloc
in the raw code at the top of the file.

And the first decision is instantly made: since this is only a default,
certainly we should use "char *", and not something special. Hmm... 

  char *Name <- Letter LetterOrDigit*

The value is the text matched. We've said that in general a missing
expression is an error, unless the only thing happening here is a call,
in which case the value is simply propagated. So that normally

  A <- B

means

  A <- b:B -> b

But these two defaults can collide. In this grammar:

  char *Name <- NamePlus
  char *NamePlus <- l:Letter LetterOrDigit* -> l

does Name get the value of all the text it matches, or the value of the
solitary call? Ways out: 1) introduce "text" and say that solitary call
is indeed the default for all types except "text", which otherwise
behaves identically to "char *". 2) Say that, for "char *" only, matched
text beats solitary call: write "char *Name <- np:NamePlus -> np" when
that's what you want. 3) Do away with one of the defaults altogether:
3a) just say that solitary call is not a default; 3b) say that we use
Piumarta-style bra kets to mark the matched text. 4) Provide a function
/ macro that means "all the matched text".

I don't like any of these!

2009-06-26
----------

OK, what I have right now is a "match()" macro, which returns the text
matched by the entire rule. It's kinda groovy, but considering cases
like this:

  char *Ident ← IdentStart IdentCont* { match() } Spacing
  void Spacing ← (' ' / '\t')*

it's a pity that match() will return the Spacing too.

(By the way, I think it would be insane to have anything like match() as
a default! It allocates memory...)

It would be easy to store the column where an expression is encountered
so that the above would work. (I was considering lmatch(), rmatch(), and
match(), which respectively match everything before, after the
expression; or the entire text matched by the rule. In fact, it would be
simpler just to have match() and rmatch(), which match to the left and
right respectively; if you want the entire expression, put match() at
the end - or rmatch() at the beginning.)

Arguably, Piumarta's bra & ket syntax is even more flexible, and there
are times when that flexibility is warranted.

  char *String ← '"' < [^"]* > '"' Spacing

(Note that this doesn't allow a string to contain " characters.)

  char *String ← '"' d:StrEsc '"' Spacing → d
  StrEsc ← ( '\\' . / . )* { match() }

Combination of match() with stashing col_expr handles all the simple
cases. And particularly if we allow binding to anything (by generating
extra rules), you can get this, which is barely even any longer.

  char *String ← '"' d:([^"]*) '"' Spacing → d

Here's a wacky one: why not phrase that as

  char *String ← '"' =:([^"]*) '"' Spacing

Oh dear, oh dear. Stop it now. Make match() work as you said you could,
and move on. We can always revisit this later.

OK, match() means lmatch(), and rmatch() exists. Cool.


Here's a bit of a puzzle that I really don't know the answer to. First,
is it permitted to have more than one expression per rule? For example,
what about something like this.

  char *Concat ← Word { a = match() } '^' { b = rmatch() } Word { strcat(a,b) }

Well, no, it certainly will never be possible to bind names in an
expression. At best, all bar the rightmost expression are evaluated - as
expressions - in a void context, as if left-hand operands of ",".

Anycase, the obvious thing to do at this stage is to say that there can
only be one expression per rule. Or rather, one active expression per
rule: we need this to work.

  int Digit ← '5' { 5 } / '6' { 6 }

So the top-level of a rule can be an alt, in which case each leg of the
alt can have its own expr. But what about non-top-level alts?

  <example here>

2009-06-27
----------

A showstopper?

I'm starting to close the loop, since pacc is almost clever enough to
emit a parser that can read its own grammar. However...

    char *Item ← s:Whatever { n = s_new(rule); n->text = s; n; }

The idea of semantic expressions starts to look a bit murky.

We could just say that we don't care: you must define functions like

    struct s_node *new_rule(char *t) {
	struct s_node *r = s_new(rule);
	if (r) r->text = t;
    }

    char *Item ← s:Whatever { new_rule(s) }

Is that too draconian?

2009-06-30
----------

Blimey. Here's something really mad. If we keep the number of specials
in the grammar really small, then instead of this::

     int Additive <- m:Multitive PLUS a:Additive { m + a } / Multitive

you could instead say this::

     int Additive <- m:Multitive + a:Additive { m + a } / Multitive

This is a really groovy idea, but we almost certainly do need at least
the characters ?*+.(){}/<>-"!: which doesn't leave many. Darn.

2009-07-07
----------

Repetition: star, plus, query. I'm minded to implement a generic
repetition operator, that matches any number of reps between a given min
and max (with max = 0 implying infinity). Thus query is rep(0,1), plus
is rep(1,0), and star is rep(0,0). (Interesting that this covers 3 out
of four quadrants: the fourth - rep(1,1) - is simply a normal match.)

This would also allow rep(2,3), for instance, although we currently
don't have a syntax for that. Errm, I guess "x @ 2 3" would do at least
as a straw man.

Now, the only possible hitch here is that we now need a s_node of type
"rep" to hold two integers. Do we just add them into struct? Or union
them with char *text? Or have some kinda "number" s_type, that we can
hang off "rep", like "call"s hang off "bind"s?

2009-07-24
----------

Well, repetitions work as advertised. However, I believe that although
the direct implementation is very straightforward, we must in fact
desugar repetitions into alts and seqs. If not, we risk the parser
becoming non-linear. (I need to cook up a test case which does in fact
show non-linearity here.) Basically the point is that only an entire
rule is memoized; if repetitions don't utilize rules, they are not
memoized. I'm inclined to leave the working repetition code for the time
being, though.

2009-09-17
----------

OK, so there's been a bit of a hiatus, but now I'm back on the case. The
file paccman.c contains code to build, manually, a tree that will
represent a parser for PEG itself. This needs to be copied to mktree.c
(and there is also a slightly customised foo.c to go with it for now).

Call the (fully-featured) language that pacc will understand tPEG. Call
a simplified version of this sPEG. Then the code in paccman.c builds a
parser for sPEG. 

We will also need a definition of tPEG written in sPEG. This will be
called, say, pacc.pacc. The parser built by paccman.c will read
pacc.pacc, and build a parser for tPEG.

What, if any, are the differences between sPEG and tPEG? Obvious
candidates include constructs that will eventually be desugared, such as
repetitions. And where there are alternate syntaxes, for example "←" or
"<-", sPEG need only support one alternative. And sPEG need not
understand defaults, such as default types, nor comments.

So it's going to be useful actually to *define* sPEG and tPEG. OK.

There's some other stuff going on too. In syntax.c we are starting to
acquire tree builders (with unsatisfactory names like mkcall(); would
not s_new_call() or s_call() do as well, if not better?). These are
necessary because we have semantic *expressions*, not actions, in pacc.
So for example, the matcher that calls another rule definition is
expressed like this.

    struct s_node *SeqRule ← i:Identifier { mkcall(i) }

Thing is, these tree builders are mighty useful. We ought to use them in
paccman.c itself. In fact, we ought to rewrite *all* the examples and
test cases we have so far to utilize the tree builders.

Or maybe not. After all, they need to be convenient to express trees as
built by pacc, not manually. Let's get the parser going first, then see
if we want to rewrite anything!

2009-09-30
----------

Major progress on the parser, but I've run into a tricky problem with
bind / guard. When a name is bound, bind_pre() calls pushcol() to record
the column where it will be bound. Then emit_expr() popcol()s each
column from col_stack to do the actual binding. Note that emit_expr()
assumes that all names in scope will be bound.

Guards, on the other hand, declare which identifiers they will bind, and
guard_pre() uses this information to bind only those, *without* calling
popcol(). It finds the appropriate column from the thrs stack. Needless
to say, this means that there are more pushes than pops of the
col_stack, and hilarity ensues.

Obviously the right fix is to make exprs follow guards, and declare
which identifiers they need bound. (Apart from anything else, what
happens if you have two exprs in a seq?)

This is easy enough to do, but the hard part is that almost every test
case, and certainly every rule in paccman.c will need to be rewritten.
So, just for a temporary workaround, I've made guard_pre() call popcol()
once for each binding.

2009-10-02
----------

Ugly hacking session, all is confusion. I have a feeling that the
intermediate results matrix is built funny. I don't really care, since
it's going away soon, but it doesn't help my head!

2009-10-03
----------

OK, so the problem is with getting the right column for bindings.
Suppose we decide that the parse we are working on will need to evaluate
a thunk, which binds names "a" and "c"... we need to push onto the
thr_stack the columns at which those names were bound. (Note that we
must be prepared to undo this if we abandon this parse, but I think
that's handled fine already by restoring thrs_ptr.)

So, when we see the binding of "a", we need to record the current
column. This can't simply go straight onto the stack already, because we
don't know what thunk(s) are coming up, nor yet what names they will
need. (What about "b", which was bound, but is unused in a given thunk?)

Currently, there is a single list of names encountered and the columns
at which they occur (oh, well, actually two coupled lists). That might
work, but we will need to save / restore its pointer along with all the
others. Hmm... let's have another look.

No, it's hairier than that. What col we are at is dynamic (in the
parser), whereas what names are bound is static (in the
parser-generator).

2009-10-08
----------

I seem to have all the above worked out, and almost working. I'm about
to wave a wand of simplification over the thrs array. Here goes...

2009-10-14
----------

Interesting, becoming an expert in a system which doesn't yet exist!
I've been trying (once again) to get my head around how we can tell
where a rule ends. For quite a while, I was under the mistaken
impression that Ford can parse "a <- b c <- d" because the parser backs
up when it sees the second arrow, and decides that the "c" must belong
to a new rule. This isn't how PEGs work!

In fact, Ford can tell where a rule ends, because every rule *ends* with
an expression "a <- b -> foo c <- d -> bar". Since only one thing
appears to the right of a right arrow, the "c" must start a new rule.
OK.

D'oh! And Piumarta solves it so easily, by saying that an identifier
that is a call is "identifier !EQUAL". Guess who'd forgotten about
syntactic predicates?
